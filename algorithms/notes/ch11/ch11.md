# chpater 10

## 11.1 direct address hash table

search (T, k): return T[k]

insert (T, x): T[x.key] = x

delete (T, x): T[x.key] = None

### Q

11.1-1: O(m) linkedlist

11.1-2: each bit stand for each position

11.1-3: so multiple values may share the same key, satelite data better as a doubled-linked list

11.1-4: Not solved

## 11.2 hash table

- difference with direct list:
  - direct list: k -> list[k]
  - hash table: h(k) -> list[h(k)]

- hash table:
  - a mapping from U space (k in U) to [0 .. m]

- chaining when conflicting

  double head chain is faster for deletion, since single linked chain need to go another round to find prev

- on average, there will be alpha = n/m elements in the chain, alpha is also called load factor,

### Q

11.2-1: n/m

11.2-2: 5, 1, ,1, 6, 2, 6, 3, 8, 1

11.2-3:
non-suceed search: o(1)
search: o(alpha + 1)
delete: o(1)
insert: o(alpha)

11.2-4: single is enough

11.2-5: if u > nm, there must be at least n numbers to be in one hash key when hash U

11.2-6: too complicated, not solved


## 11.3 hash function

- what makes a good hash function:
  - uniform distribution, each key possiblly mapping to any of 1..m. normally, we have a r is a real random distributed, and use r*m to have distribution from 0 to m

- division method: h(h) = k mod m
  - avoid certain values of m, e.g. m = 2 ** p, => h(k) is p lower bits
  - so m = 2**p - 1 could be a good choice
  - or a prime not near any power of 2

- multiply: (m (kA mod 1)),
  - 0<A<1, and get the fractional part of kA, then multiply m
  - now m is not critical, we can choose as 2 ** p
  - normally choose A = s/2**n ~ (sqrt(5)- 1)/2 = 0.6180339887, where n is the word size of the machine, e.g. 32 bits

- universal hashing: what ever k select, it's collision prob < 1/m
  - choose the hash function randomly in a way that is independent of the keys that are actually going to be stored
  - design a universal hashing: ((ak + b) mod p) mod m, a in {1, ..., p-1}, b in {0, ..., p - 1}, p is a primary number large enough so k < p

e.g.
let m = 6, p = 17, a = 3, b = 4
h(8) = 5

  - it is called universal, because, if k != l, then
    r = (ak + b) % p
    s = (al + b) % p

    r-s = a(k-l) % p != 0 since p is primary number;
    so h(k) == h(l) only if r == s % m, the probability is 1/m

### Q

11.3-1: first find the hashed value in the table, search key in the linked list, avoid to direct compare the string
11.3-2: need number theory
11.3-3: (h(k1) * 2**n + h(k2)) % (2**n - 1) = h(k1) + h(k2)
11.3-4: not solved
11.3-5: need number theory

## 11.4 open addressing

- no chaining, store at h(k, 0) if available, else h(k, 1), else h(k, 2), and so on

- this called probe sequence, so the probe not start from 0, but h(k,0)

- insert, from i = 0, search the first empty slot or '__DELETE__' mark from h(k, i)

- search,  from i = 0, search the matched value (matching) or first empty slot (no matching)

- delete: added a special mark '__DELETED__'

- probe function

  - linear h(k, i) = ( h'(k) + i ) mod m

  - quadratic: h(k, i) = (h'(k) + c1* i + c2 * i^2) mod m

  - double hashing: h(k, i) = ( h1(k) + i * h2(k) ) mod m
    - most reliable since very close to random distribution
    - method 1: A convenient way to ensure this condition is to let m be a power of 2 and to design h2 so that it always produces an odd number.
    - method 2: let m be prime and to design h2 so that it always returns a positive integer less than m
    e.g. h1 = k % m, h2 = 1 + k % (m - 1)

    - drawbacks: not always have m as prime or power of 2
    


- analysis

  - average probe times : 1//(1-alpha)
    alpha = n/m < 1

### Q

11.4-1:
compuated

11.4-2: skipped

11.4-3: 1/(1-3/4) = 4, 1/(1-7/8) = 8

11.4-4: skippep, number theory

11.4-5: not solved

## 11.5 perfect hashing


- first hash table: universal hashing: n => m

- secondary hash table: instead of chained linked list, m_j = n_j ^ 2

- n key => m hash table, and secondary hash table m_j = n_j ^ 2, P(memory >= 4n) < 1/2

### Q: skipped

## Questions:
 too difficult
